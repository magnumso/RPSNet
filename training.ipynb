{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from data import RPSDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import random\n",
    "from model_architecture import RPSNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture again (must match the saved model's architecture)\n",
    "model = RPSNet(num_classes=4);\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load(\"trained_model_5.pth\"))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device);\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 416, 416).to(device)\n",
    "output = model(dummy_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 416, 416]             216\n",
      "       BatchNorm2d-2          [-1, 8, 416, 416]              16\n",
      "              Mish-3          [-1, 8, 416, 416]               0\n",
      "         ConvBlock-4          [-1, 8, 416, 416]               0\n",
      "            Conv2d-5          [-1, 8, 208, 208]             576\n",
      "       BatchNorm2d-6          [-1, 8, 208, 208]              16\n",
      "              Mish-7          [-1, 8, 208, 208]               0\n",
      "         ConvBlock-8          [-1, 8, 208, 208]               0\n",
      "            Conv2d-9          [-1, 2, 208, 208]             144\n",
      "      BatchNorm2d-10          [-1, 2, 208, 208]               4\n",
      "             Mish-11          [-1, 2, 208, 208]               0\n",
      "        ConvBlock-12          [-1, 2, 208, 208]               0\n",
      "           Conv2d-13          [-1, 2, 208, 208]             180\n",
      "      BatchNorm2d-14          [-1, 2, 208, 208]               4\n",
      "             Mish-15          [-1, 2, 208, 208]               0\n",
      "        ConvBlock-16          [-1, 2, 208, 208]               0\n",
      "           Conv2d-17          [-1, 2, 208, 208]             216\n",
      "      BatchNorm2d-18          [-1, 2, 208, 208]               4\n",
      "             Mish-19          [-1, 2, 208, 208]               0\n",
      "        ConvBlock-20          [-1, 2, 208, 208]               0\n",
      "           Conv2d-21          [-1, 2, 208, 208]             252\n",
      "      BatchNorm2d-22          [-1, 2, 208, 208]               4\n",
      "             Mish-23          [-1, 2, 208, 208]               0\n",
      "        ConvBlock-24          [-1, 2, 208, 208]               0\n",
      "       DenseBlock-25         [-1, 16, 208, 208]               0\n",
      "           Conv2d-26         [-1, 16, 208, 208]           2,304\n",
      "      BatchNorm2d-27         [-1, 16, 208, 208]              32\n",
      "             Mish-28         [-1, 16, 208, 208]               0\n",
      "        ConvBlock-29         [-1, 16, 208, 208]               0\n",
      "           Conv2d-30         [-1, 16, 104, 104]           2,304\n",
      "      BatchNorm2d-31         [-1, 16, 104, 104]              32\n",
      "             Mish-32         [-1, 16, 104, 104]               0\n",
      "        ConvBlock-33         [-1, 16, 104, 104]               0\n",
      "           Conv2d-34          [-1, 4, 104, 104]             576\n",
      "      BatchNorm2d-35          [-1, 4, 104, 104]               8\n",
      "             Mish-36          [-1, 4, 104, 104]               0\n",
      "        ConvBlock-37          [-1, 4, 104, 104]               0\n",
      "           Conv2d-38          [-1, 4, 104, 104]             720\n",
      "      BatchNorm2d-39          [-1, 4, 104, 104]               8\n",
      "             Mish-40          [-1, 4, 104, 104]               0\n",
      "        ConvBlock-41          [-1, 4, 104, 104]               0\n",
      "           Conv2d-42          [-1, 4, 104, 104]             864\n",
      "      BatchNorm2d-43          [-1, 4, 104, 104]               8\n",
      "             Mish-44          [-1, 4, 104, 104]               0\n",
      "        ConvBlock-45          [-1, 4, 104, 104]               0\n",
      "           Conv2d-46          [-1, 4, 104, 104]           1,008\n",
      "      BatchNorm2d-47          [-1, 4, 104, 104]               8\n",
      "             Mish-48          [-1, 4, 104, 104]               0\n",
      "        ConvBlock-49          [-1, 4, 104, 104]               0\n",
      "       DenseBlock-50         [-1, 32, 104, 104]               0\n",
      "           Conv2d-51         [-1, 32, 104, 104]           9,216\n",
      "      BatchNorm2d-52         [-1, 32, 104, 104]              64\n",
      "             Mish-53         [-1, 32, 104, 104]               0\n",
      "        ConvBlock-54         [-1, 32, 104, 104]               0\n",
      "           Conv2d-55           [-1, 32, 52, 52]           9,216\n",
      "      BatchNorm2d-56           [-1, 32, 52, 52]              64\n",
      "             Mish-57           [-1, 32, 52, 52]               0\n",
      "        ConvBlock-58           [-1, 32, 52, 52]               0\n",
      "           Conv2d-59            [-1, 8, 52, 52]           2,304\n",
      "      BatchNorm2d-60            [-1, 8, 52, 52]              16\n",
      "             Mish-61            [-1, 8, 52, 52]               0\n",
      "        ConvBlock-62            [-1, 8, 52, 52]               0\n",
      "           Conv2d-63            [-1, 8, 52, 52]           2,880\n",
      "      BatchNorm2d-64            [-1, 8, 52, 52]              16\n",
      "             Mish-65            [-1, 8, 52, 52]               0\n",
      "        ConvBlock-66            [-1, 8, 52, 52]               0\n",
      "           Conv2d-67            [-1, 8, 52, 52]           3,456\n",
      "      BatchNorm2d-68            [-1, 8, 52, 52]              16\n",
      "             Mish-69            [-1, 8, 52, 52]               0\n",
      "        ConvBlock-70            [-1, 8, 52, 52]               0\n",
      "           Conv2d-71            [-1, 8, 52, 52]           4,032\n",
      "      BatchNorm2d-72            [-1, 8, 52, 52]              16\n",
      "             Mish-73            [-1, 8, 52, 52]               0\n",
      "        ConvBlock-74            [-1, 8, 52, 52]               0\n",
      "       DenseBlock-75           [-1, 64, 52, 52]               0\n",
      "           Conv2d-76           [-1, 64, 52, 52]          36,864\n",
      "      BatchNorm2d-77           [-1, 64, 52, 52]             128\n",
      "             Mish-78           [-1, 64, 52, 52]               0\n",
      "        ConvBlock-79           [-1, 64, 52, 52]               0\n",
      "           Conv2d-80           [-1, 64, 26, 26]          36,864\n",
      "      BatchNorm2d-81           [-1, 64, 26, 26]             128\n",
      "             Mish-82           [-1, 64, 26, 26]               0\n",
      "        ConvBlock-83           [-1, 64, 26, 26]               0\n",
      "           Conv2d-84           [-1, 16, 26, 26]           9,216\n",
      "      BatchNorm2d-85           [-1, 16, 26, 26]              32\n",
      "             Mish-86           [-1, 16, 26, 26]               0\n",
      "        ConvBlock-87           [-1, 16, 26, 26]               0\n",
      "           Conv2d-88           [-1, 16, 26, 26]          11,520\n",
      "      BatchNorm2d-89           [-1, 16, 26, 26]              32\n",
      "             Mish-90           [-1, 16, 26, 26]               0\n",
      "        ConvBlock-91           [-1, 16, 26, 26]               0\n",
      "           Conv2d-92           [-1, 16, 26, 26]          13,824\n",
      "      BatchNorm2d-93           [-1, 16, 26, 26]              32\n",
      "             Mish-94           [-1, 16, 26, 26]               0\n",
      "        ConvBlock-95           [-1, 16, 26, 26]               0\n",
      "           Conv2d-96           [-1, 16, 26, 26]          16,128\n",
      "      BatchNorm2d-97           [-1, 16, 26, 26]              32\n",
      "             Mish-98           [-1, 16, 26, 26]               0\n",
      "        ConvBlock-99           [-1, 16, 26, 26]               0\n",
      "      DenseBlock-100          [-1, 128, 26, 26]               0\n",
      "          Conv2d-101          [-1, 128, 26, 26]         147,456\n",
      "     BatchNorm2d-102          [-1, 128, 26, 26]             256\n",
      "            Mish-103          [-1, 128, 26, 26]               0\n",
      "       ConvBlock-104          [-1, 128, 26, 26]               0\n",
      "          Conv2d-105          [-1, 128, 13, 13]         147,456\n",
      "     BatchNorm2d-106          [-1, 128, 13, 13]             256\n",
      "            Mish-107          [-1, 128, 13, 13]               0\n",
      "       ConvBlock-108          [-1, 128, 13, 13]               0\n",
      "          Conv2d-109           [-1, 32, 13, 13]          36,864\n",
      "     BatchNorm2d-110           [-1, 32, 13, 13]              64\n",
      "            Mish-111           [-1, 32, 13, 13]               0\n",
      "       ConvBlock-112           [-1, 32, 13, 13]               0\n",
      "          Conv2d-113           [-1, 32, 13, 13]          46,080\n",
      "     BatchNorm2d-114           [-1, 32, 13, 13]              64\n",
      "            Mish-115           [-1, 32, 13, 13]               0\n",
      "       ConvBlock-116           [-1, 32, 13, 13]               0\n",
      "          Conv2d-117           [-1, 32, 13, 13]          55,296\n",
      "     BatchNorm2d-118           [-1, 32, 13, 13]              64\n",
      "            Mish-119           [-1, 32, 13, 13]               0\n",
      "       ConvBlock-120           [-1, 32, 13, 13]               0\n",
      "          Conv2d-121           [-1, 32, 13, 13]          64,512\n",
      "     BatchNorm2d-122           [-1, 32, 13, 13]              64\n",
      "            Mish-123           [-1, 32, 13, 13]               0\n",
      "       ConvBlock-124           [-1, 32, 13, 13]               0\n",
      "      DenseBlock-125          [-1, 256, 13, 13]               0\n",
      "          Conv2d-126          [-1, 256, 13, 13]         589,824\n",
      "     BatchNorm2d-127          [-1, 256, 13, 13]             512\n",
      "            Mish-128          [-1, 256, 13, 13]               0\n",
      "       ConvBlock-129          [-1, 256, 13, 13]               0\n",
      "          Conv2d-130          [-1, 256, 13, 13]         589,824\n",
      "     BatchNorm2d-131          [-1, 256, 13, 13]             512\n",
      "            Mish-132          [-1, 256, 13, 13]               0\n",
      "       ConvBlock-133          [-1, 256, 13, 13]               0\n",
      "          Conv2d-134           [-1, 64, 13, 13]         147,456\n",
      "     BatchNorm2d-135           [-1, 64, 13, 13]             128\n",
      "            Mish-136           [-1, 64, 13, 13]               0\n",
      "       ConvBlock-137           [-1, 64, 13, 13]               0\n",
      "          Conv2d-138           [-1, 64, 13, 13]         184,320\n",
      "     BatchNorm2d-139           [-1, 64, 13, 13]             128\n",
      "            Mish-140           [-1, 64, 13, 13]               0\n",
      "       ConvBlock-141           [-1, 64, 13, 13]               0\n",
      "          Conv2d-142           [-1, 64, 13, 13]         221,184\n",
      "     BatchNorm2d-143           [-1, 64, 13, 13]             128\n",
      "            Mish-144           [-1, 64, 13, 13]               0\n",
      "       ConvBlock-145           [-1, 64, 13, 13]               0\n",
      "          Conv2d-146           [-1, 64, 13, 13]         258,048\n",
      "     BatchNorm2d-147           [-1, 64, 13, 13]             128\n",
      "            Mish-148           [-1, 64, 13, 13]               0\n",
      "       ConvBlock-149           [-1, 64, 13, 13]               0\n",
      "      DenseBlock-150          [-1, 512, 13, 13]               0\n",
      "          Conv2d-151            [-1, 4, 13, 13]           2,052\n",
      "================================================================\n",
      "Total params: 2,658,276\n",
      "Trainable params: 2,658,276\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 137.65\n",
      "Params size (MB): 10.14\n",
      "Estimated Total Size (MB): 149.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "summary(model, input_size=(3, 416, 416), device=str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([8, 3, 416, 416])\n",
      "Labels batch shape: torch.Size([8, 4])\n",
      "\n",
      "Images validation batch shape: torch.Size([8, 3, 416, 416])\n",
      "Labels validation batch shape: torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "# Training dataset path\n",
    "img_dir = \"Dataset-5/train/images\"\n",
    "labels_dir = \"Dataset-5/train/labels\"\n",
    "\n",
    "# Validation dataset path\n",
    "validation_labels_dir = \"Dataset-5/valid/labels\"\n",
    "validation_img_dir = \"Dataset-5/valid/images\"\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = RPSDataset(img_dir, labels_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "validation_dataset = RPSDataset(validation_img_dir, validation_labels_dir)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size, shuffle=True)\n",
    "\n",
    "# Display size of the batch sizes\n",
    "for images, labels in dataloader:\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "for images, labels in validation_dataloader:\n",
    "    print(\"Images validation batch shape:\", images.shape)\n",
    "    print(\"Labels validation batch shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_function, optimizer, num_epochs):\n",
    "    # Train on cuda if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "    \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            true_labels = torch.argmax(labels, dim=1)\n",
    "            correct_train += (preds == true_labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        # Get and display the loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Epoch {epoch + 1} / {num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation loss and accuracy\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss = loss_function(val_outputs, val_labels)\n",
    "                val_running_loss += val_loss.item() * val_images.size(0)\n",
    "                \n",
    "                # Calculate validation accuracy\n",
    "                val_preds = torch.argmax(val_outputs, dim=1)\n",
    "                val_true_labels = torch.argmax(val_labels, dim=1)\n",
    "                correct_val += (val_preds == val_true_labels).sum().item()\n",
    "                total_val += val_labels.size(0)\n",
    "\n",
    "        # Display the validation loss and accuracy\n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracy = correct_val / total_val\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Epoch {epoch + 1} / {num_epochs}, Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "# Train the model and save it\n",
    "save_path = \"RPSNet/trained_model_5.pth\"\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train(model, dataloader, validation_dataloader, loss_function, optimizer, num_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display metrics\n",
    "Display the metrics of the model which is used in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracies(train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, class_names):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            true_labels = torch.argmax(labels, dim=1).cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(true_labels)\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "class_names = ['Paper', 'Rock', 'Scissor', 'None']\n",
    "\n",
    "# Evaluate the model\n",
    "true_labels, predicted_labels = evaluate_model(model, validation_dataloader)\n",
    "    \n",
    "# Visualize the loss\n",
    "plot_losses(train_losses, val_losses)\n",
    "\n",
    "# Visualize the accuracy\n",
    "plot_accuracies(train_accuracies, val_accuracies)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(true_labels, predicted_labels, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
